{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module23 DNN AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute() 交換===============================\n",
    "# coding: utf-8\n",
    "import torch\n",
    "inputs = [[[1, 2 ,3], [4, 5, 6]],\n",
    "          [[7, 8, 9], [10, 11, 12]]]\n",
    "inputs = torch.tensor(inputs)\n",
    "print('inputs=\\n',inputs) ; print('Inputs.shape:', inputs.shape) \n",
    "# torch.Size([2, 2, 3]) , dim(axis) 0 is 2維, dim 1 is 2維 , dim2 is 3維 \n",
    "# permute() 則是可以透過設定 dim(axis) 這個編號，置換維度。\n",
    "outputs = inputs.permute(0, 2, 1)  # 順序改為 (dim 0, dim 2, dim 1)\n",
    "print('outputs = \\n',outputs); print('Outputs.shape:', outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view() ==============================\n",
    "import torch\n",
    "inputs = [[[1, 2 ,3], [4, 5, 6]],\n",
    "          [[7, 8, 9], [10, 11, 12]]]\n",
    "inputs = torch.tensor(inputs)\n",
    "print('inputs=\\n', inputs) ;print('Inputs.shape:', inputs.shape)\n",
    "outputs = inputs.view(2, 3, 2)\n",
    "print('outputs =\\n',outputs) ;  print('Outputs.shape:', outputs.shape)\n",
    "outputs = inputs.view(-1)  # 不指定維度形狀，將所有元素放在同一維度下(1排)\n",
    "print(outputs) ;  print('Outputs:', outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cat() 的使用方法 =======================\n",
    "import torch\n",
    "a = torch.tensor([1, 2, 3]) ;  b = torch.tensor([4, 5, 6])\n",
    "ab = torch.cat((a, b),0)  # 0 & -1 (-1就是不指定) 結果一樣\n",
    "ba = torch.cat((b, a), 0) ;  print('ab:', ab) ;  print('ba:', ba)\n",
    "#=========================\n",
    "a = torch.tensor([[1, 2, 3]])   ;   b = torch.tensor([[4, 5, 6]])\n",
    "print('0:', torch.cat((a, b), 0)) ;  print('1:', torch.cat((a, b), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "epochs = 10  ;   batch_size = 128  ;lr = 0.008  # learning rate\n",
    "# DataLoader\n",
    "train_set = torchvision.datasets.MNIST(root='./dataset/mnist',train=True,\n",
    "    download=True, transform=torchvision.transforms.ToTensor(),)\n",
    "train_loader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 2), )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Sigmoid() )\n",
    "    def forward(self, inputs):\n",
    "        codes = self.encoder(inputs)\n",
    "        decoded = self.decoder(codes)\n",
    "        return codes, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "model = AutoEncoder()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "for epoch in range(epochs):\n",
    "    for batch_data, labels in train_loader:\n",
    "        inputs = batch_data.view(-1, 784)\n",
    "        # Forward\n",
    "        codes, decoded = model(inputs)\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(decoded, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Show progress\n",
    "    print('[{}/{}] Loss:'.format(epoch+1, epochs), loss.item())\n",
    "# Save\n",
    "torch.save(model, 'autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Settings\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "# Show images\n",
    "def show_images(images):\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(sqrtn, sqrtn, index+1)\n",
    "        plt.imshow(image.reshape(28, 28))\n",
    "        plt.axis('off')\n",
    "# Model structure\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(   # Encoder\n",
    "            nn.Linear(784, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 2), )\n",
    "        self.decoder = nn.Sequential(  # Decoder\n",
    "            nn.Linear(2, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Sigmoid() )\n",
    "    def forward(self, inputs):\n",
    "        codes = self.encoder(inputs)\n",
    "        decoded = self.decoder(codes) ; return codes, decoded\n",
    "# Load model\n",
    "model = torch.load('autoencoder.pth')\n",
    "model.eval()  ; print(model)\n",
    "# DataLoader\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root='./dataset/mnist',\n",
    "    train=False, download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),)\n",
    "test_loader = data.DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for batch_data in test_loader:\n",
    "        inputs = batch_data[0].view(-1, 28*28)\n",
    "        show_images(inputs)  ;   plt.show()\n",
    "        code, outputs = model(inputs)\n",
    "        show_images(outputs)  ; plt.show() ;  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE : 受歡迎的 autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "#torch.cuda.set_device(1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sample_dir = 'samples'        # 結果放置目錄\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 784  ;  h_dim = 400  ;  z_dim = 20 \n",
    "num_epochs = 15   ;  batch_size = 128  ; learning_rate = 1e-3\n",
    "dataset = torchvision.datasets.MNIST(root='./dataset/mnist',train=True,\n",
    "                           transform=transforms.ToTensor(),download=True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):   ## VAE model\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoder ==============================\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)  # fc2, fc3 一樣\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim) \n",
    "        # decoder =============================\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)  # 兵分1個兩路, 1給 mean , 1個給std\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2) ;  eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))  ; return F.sigmoid(self.fc5(h))\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)  ; return x_reconst, mu, log_var\n",
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        # page 23-19 ========================\n",
    "        # 1 reconstruction loss-----------------------------------------\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        # 2 KL deviation loss\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        loss = reconst_loss + kl_div  # 1+2 --> 做優化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg \n",
    "import numpy as np\n",
    "reconsPath = './samples/reconst-15.png'\n",
    "Image = mpimg.imread(reconsPath)\n",
    "plt.imshow(Image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "genPath = './samples/sampled-15.png'\n",
    "Image = mpimg.imread(genPath)\n",
    "plt.imshow(Image) \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
