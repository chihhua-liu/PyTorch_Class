{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 15: NLP & Word2vec :  Embedding Layer : 把ID 變成向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "docs = [\n",
    "    \"新的數學方法和概念，常常比解決數學問題本身更重要。\",\n",
    "    \"在數學中，我們發現真理的主要工具是歸納和模擬。\",\n",
    "    \"數學方法滲透並支配著一切自然科學的理論分支。它愈來愈成為衡量科學成就的主要標志了。\",\n",
    "    \"第一是數學，第二是數學，第三是數學。\",\n",
    "    \"歷史使人賢明，詩造成氣質高雅的人，數學使人高尚，自然哲學使人深沈，道德使人穩重，倫理學和修辭學\"]\n",
    "# jieba for 斷詞 \n",
    "import jieba\n",
    "words_list = [list(jieba.cut(doc)) for doc in docs]\n",
    "print(words_list)\n",
    "# build word dictionary\n",
    "vocb = set([word for words in words_list for word in words])\n",
    "word_to_idx = {word: i for i, word in enumerate(vocb)}\n",
    "idx_to_word = {word_to_idx[word]: word for word in word_to_idx}\n",
    "print('vocb = \\n',vocb)\n",
    "print('word_to_idx = \\n',word_to_idx)\n",
    "print('idx_to_word = \\n',idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocb_size = len(vocb)\n",
    "embedding_size = 200\n",
    "embeds = nn.Embedding(vocb_size, embedding_size) \n",
    "print(embeds)\n",
    "# 文字1 -> 轉換成 字ID --> 經過 embedding layer 轉換成  word embedding\n",
    "print(word_to_idx[\"數學\"])\n",
    "look_up = torch.LongTensor([word_to_idx[\"數學\"]])\n",
    "print(embeds(look_up).shape)\n",
    "print(embeds(look_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-trained word2vect : * 直接使用訓練好的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim      # 適合做word2vec 的 model\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "# download the model and return as object ready for use\n",
    "word2vec_model = api.load(\"glove-twitter-25\")  # change 25維向量 \n",
    "#word2vec_model = gensim.models.KeyedVectors.load(\"news.word2vec\")\n",
    "embedding_shape = word2vec_model.vectors.shape\n",
    "print(embedding_shape) # 1193514 個字，每個字25維向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "#initialized embedding layer :embedding_shape[0] =1193514 embedding_shape[1]=25\n",
    "embed = nn.Embedding(embedding_shape[0], embedding_shape[1])\n",
    "#copy pre-trained word2vect model\n",
    "embed.weight.data.copy_(torch.from_numpy(word2vec_model.vectors))\n",
    "#freeze weight\n",
    "embed.weight.requires_grad = False # 固定參數，不讓微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = word2vec_model.key_to_index[\"happy\"] # key_to_index :給英文字 得ID(index)\n",
    "#查表\n",
    "print(embed(torch.LongTensor([index])).shape) # ID(index) 轉換 vectot(tensor)\n",
    "print(embed(torch.LongTensor([index]))) \n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.vectors[5160]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word to Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [[\"i\",\"am\",\"good\",\"guy\"],[\"delicious\",\"food\"]]\n",
    "for doc in docs:\n",
    "    for word in doc:\n",
    "        word2vec_model.key_to_index[word]\n",
    "indexes = [[word2vec_model.key_to_index[word] for word in doc] for doc in docs]\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_indexes = (np.array(indexes))\n",
    "print(np_indexes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
