{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "`pip install tensorboardX`  \n",
    "`pip install tensorflow`  \n",
    "`pip install Tensorboard_logger`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "epoch: 0, Train Loss: 0.576153, Train Acc: 0.827325, Eval Loss: 0.225410, Eval Acc: 0.929589\n",
      "epoch: 1, Train Loss: 0.155342, Train Acc: 0.953475, Eval Loss: 0.113504, Eval Acc: 0.965487\n",
      "epoch: 2, Train Loss: 0.100182, Train Acc: 0.969600, Eval Loss: 0.111441, Eval Acc: 0.964300\n",
      "epoch: 3, Train Loss: 0.072614, Train Acc: 0.977962, Eval Loss: 0.077777, Eval Acc: 0.974782\n",
      "epoch: 4, Train Loss: 0.056346, Train Acc: 0.982693, Eval Loss: 0.076018, Eval Acc: 0.975475\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "def data_transform(x):\n",
    "    x = np.array(x, dtype = 'float32') / 255\n",
    "    x = x.reshape((-1, ))\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "trainset = mnist.MNIST('./dataset/mnist', train=True, transform=data_transform, download=True)\n",
    "testset = mnist.MNIST('./dataset/mnist', train = False, transform=data_transform, download=True)\n",
    "\n",
    "train_data = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "writer = SummaryWriter('./tensorboard_logs2')\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        self.fc4 = nn.Linear(125, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# build model\n",
    "model = DNN().to(device)\n",
    "\n",
    "# define cost\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimization\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.1)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), 0.01, alpha=0.9)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), 0.01, betas=(0.9, 0.99))\n",
    "\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()      \n",
    "    \n",
    "    for index, (im, label) in enumerate(train_data):\n",
    "        \n",
    "        im = im.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(im)\n",
    "        \n",
    "        loss = criterion(pred, label)\n",
    "        \n",
    "        writer.add_scalar('Loss', loss, epoch * len(trainset.data)//64 + index)\n",
    "        \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "\n",
    "        _, pred = pred.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / im.shape[0]\n",
    "        writer.add_scalar('Accuracy', acc,  epoch * len(trainset.data)//64 + index)\n",
    "        train_acc += acc\n",
    "        \n",
    "        \n",
    "    losses.append(train_loss / len(train_data))\n",
    "    acces.append(train_acc / len(train_data))\n",
    "    \n",
    "\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for im, label in test_data:\n",
    "\n",
    "        im = im.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model(im)\n",
    "        loss = criterion(pred, label)\n",
    "\n",
    "        \n",
    "        eval_loss += loss.item()\n",
    "\n",
    "        \n",
    "        _, pred = pred.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / im.shape[0]\n",
    "        eval_acc += acc\n",
    "    \n",
    "    eval_losses.append(eval_loss / len(test_data))\n",
    "    eval_acces.append(eval_acc / len(test_data))\n",
    "    print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}, Eval Loss: {:.6f}, Eval Acc: {:.6f}'\n",
    "          .format(epoch, train_loss / len(train_data), train_acc / len(train_data), eval_loss / len(test_data), eval_acc / len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
