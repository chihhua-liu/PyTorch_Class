{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Practice3 : CNN for real defect Image\n",
    "##### (1) PIL(Pillow) 是 Python 中著名影像處理套件: 可用來轉檔、調色、濾鏡、浮水印甚至創造圖片一堆的功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# 1. 轉檔 : Image.open() 讀取圖片檔  =================================================================\n",
    "#           save(\"FILE NAME\",\"FORMAT\") 用來寫入圖片檔，format 其實非必須，PIL會自動透過常見副檔名來判斷格式。\n",
    "#           常用的 PIL 支援格式 :  BMP ,EPS , GIF , JPEG, PNG ,TIFF , PDF\n",
    "im = Image.open('./data_manufacture/train/Cr/cr_51.bmp') ;im.save(\"test.png\",\"png\")\n",
    "im = Image.open('./data_manufacture/train/Cr/cr_51.bmp') ;im.save(\"test.jpg\",'jpeg')\n",
    "# 2. 修改突變尺寸 :im.resize ==============================================\n",
    "im = Image.open('./data_manufacture/train/Cr/cr_51.bmp') ; print (im.size); width = 400\n",
    "ratio = float(width)/im.size[0]\n",
    "height = int(im.size[1]*ratio)\n",
    "nim = im.resize( (width, height), Image.Resampling.BILINEAR ); nim.show() ; print (nim.size)\n",
    "nim.save(\"test_resized.jpg\")\n",
    "# 3.JPG 壓縮 :save()函式中加入 quality=80, subsampling=0這兩個參數即可壓縮檔案，通常 quality 會設定80或90。\n",
    "img = Image.open('./data_manufacture/train/Cr/cr_51.bmp'); img.save(\"test_c.jpg\",quality=80,subsampling=0)\n",
    "# 4. 圖片旋轉 transpose() : Image.FLIP_LEFT_RIGHT (左右翻轉) , Image.FLIP_TOP_DOWN (上下翻轉)\n",
    "#                  Image.ROTATE_90 (旋轉90度) , Image.ROTATE_180 (旋轉180度) ,Image.ROTATE_270 (旋轉270度)\n",
    "img = Image.open('./data_manufacture/train/Cr/cr_51.bmp')\n",
    "imgR =img.transpose(Image.Transpose.ROTATE_180) ; imgR.save(\"test_R90.jpg\")\n",
    "# 5.製作縮圖 : PIL有一個專門製作縮圖的方法thumbnail()\n",
    "img = Image.open( './data_manufacture/train/Cr/cr_51.bmp' )\n",
    "img.thumbnail( (100,100) ) #指定長與寬並進行縮圖製作\n",
    "img.save( \"test_thumbnail.jpg\" ) ; print (img.size)\n",
    "# 6. 加入濾鏡 : PIL 本身就有提供一些濾鏡可以使用,img.fliter() 即可加入濾鏡\n",
    "# img.filter(ImageFilter.FIND_EDGES)\n",
    "from PIL import ImageFilter\n",
    "img = Image.open('./data_manufacture/train/Cr/cr_51.bmp' )\n",
    "img_f = img.filter(ImageFilter.FIND_EDGES)\n",
    "img_f.save(\"test_rf.jpg\"); img_f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.transforms()\n",
    "* Transforms are common image transformations.\n",
    "* They can be chained together using Compose.\n",
    "* Functional transforms give fine-grained control over the transformations. <br>\n",
    "<b> transforms.Compose([   <br>\n",
    "    transforms.CenterCrop(10),    <br>\n",
    "    transforms.Normalize((0.5, 0.4, 0.5), (0.5, 0.5, 0.5)),    \n",
    "    transforms.RandomHorizontalFlip(p=0.5),    <br>\n",
    "    transforms.RandomRotation(),    <br>\n",
    "    transforms.RandomApply(random_transforms, p=0.3),   <br>\n",
    "    transforms.ToTensor() ])</b>  \n",
    "1. class torchvision.transforms.Scale(size, interpolation=2)\n",
    "2. class torchvision.transforms.RandomCrop(size, padding=0):Crop the given PIL image at a random location.\n",
    "3. class torchvision.transforms.RandomHorizontalFlip(p=0.5):  <br>\n",
    "    Horizontally flip the given image randomly with a given probability.\n",
    "4. class torchvision.transforms.RandomRotation\n",
    "5. class torchvision.transforms.Resize(size):<br>\n",
    "   Resize the input PIL image to the given size, usually used with training_testing set\n",
    "6. class torchvision.transforms.RandomApply\n",
    "7. class torchvision.transforms.ToTensor\n",
    "8. class torchvision.transforms.Normalize(mean, std):Only use Normalize with Tensor, not PIL.image\n",
    "9. class torchvision.transforms.ToTensor // HWC > CHW : Convert PIL.image to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision模組import :\n",
    "#1.  Numpy image 和 PIL image轉換\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "img_pil = Image.open('./test1.png')\n",
    "img_pil.show()\n",
    "print(img_pil.size)\n",
    "trans_toPIL = transforms.ToPILImage() # 將  \"pytoch tensor\" 或是  \"numpy.ndarray\" 轉換成 PIL Image.\n",
    "img_np = np.asarray(img_pil) # 將PIL image轉換成  \"numpy.ndarray\" \n",
    "print('image type before convert:{}'.format(type(img_np)))\n",
    "print('img_np.shape =',img_np.shape) ; img_pil = trans_toPIL(img_np)\n",
    "print('image type after convert:{}'.format(type(img_pil)));img_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 影像 Normalize\n",
    "mean =[0.5, 0.5, 0.5] # color image : [0.5, 0.5, 0.5]\n",
    "std = [0.1, 0.1, 0.1]  # color image :[0.1, 0.1, 0.1]\n",
    "transform = transforms.Compose([     # transforms.Compose : 將 幾個處理寫在裡面\n",
    "    transforms.ToTensor(),transforms.Normalize(mean, std), transforms.ToPILImage() ])\n",
    "img_pil_normal = transform(img_pil)\n",
    "img_pil_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  3.影像 Resize : size: 可以設定一個固定長寬值，也可以長寬分別設定 ex: size=200 或是 size = (height, width) = (50,40)\n",
    "# interpolation: 圖在縮放採用的插值方法，default為PIL.Image.BILINEAR \n",
    "# 還有其他方法PIL.Image.NEAREST, PIL.Image.BILINEAR and PIL.Image.BICUBIC.可以選擇\n",
    "size = 200\n",
    "transform =  transforms.Resize(size)\n",
    "new_img = transform(img_pil)\n",
    "print(new_img.size)\n",
    "new_img.show()\n",
    "size = (200, 250)\n",
    "transform =  transforms.Resize(size)\n",
    "new_img = transform(img_pil)\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ４．影像 CenterCrop : 以圖片(PIL Image)中心點往外延伸設定的大小(size)範圍進行圖像切割。\n",
    "#  ex: size=200 則是以中心點出來，長寬個擷取200個pixels。\n",
    "# size = (height, width) = (200,300)，長擷取200個pixel，寬擷取300個pixels\n",
    "size = 200\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(size),])\n",
    "new_img = transform(img_pil)\n",
    "new_img.show()\n",
    "size = (200,100)\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(size),])\n",
    "new_img = transform(img_pil)\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　5. 影像 RandomCrop　：以圖片(PIL Image)中隨機裁減一塊圖像出來。\n",
    "#　size: 填充寬度和高度，可以為一個值(寬度和高度都用給予同樣的延伸)，或是分別對應寬度和高度設定。\n",
    "#　padding: 參照影像Pad部分\n",
    "#　pad_if_needed: 是否需要填充，True or False\n",
    "#　fill: 參照影像Pad部分\n",
    "#　padding_mode: 參照影像Pad部分\n",
    "size=(250, 300)\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(size)])\n",
    "new_img = transform(img_pil)\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 影像 RandomHorizontalFlip 和 RandomVerticalFlip\n",
    "# 圖片(PIL Image)會在給定的機率下隨機進行水平或是垂直翻轉。\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((350,350)),\n",
    "    transforms.RandomHorizontalFlip(p=0.9),])\n",
    "new_img = transform(img_pil)\n",
    "new_img.show()\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300,400)),transforms.RandomVerticalFlip(p=0.9),])\n",
    "new_img = transform(img_pil)\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.  影像 RandomResizedCrop :圖片(PIL Image)會在給定的機率下隨機 裁切到隨機給定的大小並且resize到設定的大小。\n",
    "# size: 圖片最後要輸出的大小。\n",
    "# scale: 裁切圖片為原始突變的比例(default為0.08–1.0)\n",
    "# ratio: 裁切圖片的原始長寬比(default:3/4–4/3)。\n",
    "# interpolation: check 影像 Resize。\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop((300, 500))])\n",
    "new_img = transform(img_pil)\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.影像 TenCrop: 圖片(PIL Image)裁減一張圖得四個角圖片以及中間的圖片到指定大小(size)，並且進行水平或是垂直翻轉等。\n",
    "# size: 圖片最後要輸出的大小。\n",
    "# vertical_flip: 是否垂直翻轉，預設為水平翻轉(default:False)\n",
    "UNIT_SIZE=200\n",
    "size = (100, UNIT_SIZE)\n",
    "transform = transforms.Compose([transforms.TenCrop(size, vertical_flip=False)])\n",
    "new_img = transform(img_pil)\n",
    "delta = 50 \n",
    "new_img_2 = Image.new(\"RGB\", (UNIT_SIZE*10+delta, 100))\n",
    "top_right = 0\n",
    "for im in new_img:\n",
    "    new_img_2.paste(im, (top_right, 0)) \n",
    "    top_right += UNIT_SIZE + int(delta/10) \n",
    "new_img_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  9 影像 GaussianBlur :圖片(PIL Image or torch tensor)高斯模糊化 如果為torch tensor影像必須為[…, C, H, W]。\n",
    "# 圖片(PIL Image or torch tensor)高斯模糊化 如果為torch tensor影像必須為[…, C, H, W]。\n",
    "# kernel_size: 高斯kernel的大小。\n",
    "# sigma: 高斯kernel生成的標準差，sigma值需為 1. float: (float)，\n",
    "# sigma固定在設定的float值 2. tuple: (min, max)，sigma在(min, max)隨機取出一個值。\n",
    "transform = transforms.Compose([transforms.GaussianBlur(7,3) ])\n",
    "new_img = transform(img_pil)\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 影像 Pad :以圖片(PIL Image)外部往外延伸填充寬度和高度，填充值為pad值。\n",
    "# padding: 填充寬度和高度，可以為一個值(四個邊都用給予同樣的延伸)，或是分別對應四個邊設定。\n",
    "# fill: 填充的值 設定一個值則是所有channel都填這個值 或是分別對三個channel分別設定， 須設定padding_mode=constant\n",
    "# padding_mode: 填充模式 . constant: 填充固定數字 . edge:邊緣的值直接往外延伸 . \n",
    "#               reflect: 從邊緣往內一個pixel進行鏡射 . symmetric:從邊緣鏡射\n",
    "padding = (10, 5, 40, 20)\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.Pad(padding, fill=0,padding_mode=\"constant\"), ])\n",
    "new_img = transform(img_pil)\n",
    "new_img.show()\n",
    "padding = 40\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.Pad(padding, fill=100,padding_mode=\"constant\"),])   # color image: fill=(100,200,255)\n",
    "new_img = transform(img_pil)\n",
    "new_img.show()\n",
    "padding = (40, 40, 40, 40)\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.Pad(padding, padding_mode=\"edge\"), ])\n",
    "new_img = transform(img_pil)\n",
    "new_img.show()\n",
    "padding = (40, 40, 40, 40)\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.Pad(padding, padding_mode=\"symmetric\"), ]) # symmetric :對稱\n",
    "new_img = transform(img_pil); new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 影像 RandomCrop 以圖片(PIL Image)中隨機裁減一塊圖像出來。\n",
    "# 參數設定:\n",
    "# size: 填充寬度和高度，可以為一個值(寬度和高度都用給予同樣的延伸)，或是分別對應寬度和高度設定。\n",
    "# padding: 參照影像Pad部分\n",
    "# pad_if_needed: 是否需要填充，True or False\n",
    "# fill: 參照影像Pad部分\n",
    "# padding_mode: 參照影像Pad部分\n",
    "size=(400, 200)\n",
    "transform = transforms.Compose([transforms.RandomCrop(size)])\n",
    "new_img = transform(img_pil); new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 影像 RandomAffine : 圖片(PIL Image or torch tensor)保持中心不變的圖像的隨機仿射變換。\n",
    "# degrees: 旋轉角度， 設定為0代表不做圖片旋轉。 \n",
    "#   1. float or int: 角度在(-degrees,+degrees)隨機取一個。 2. tuple: (min, max)，角度在(min, max)隨機取出一個值。\n",
    "# translate: 水平和垂直平移，defalut為不做平移。 ex: translate=(a, b)，\n",
    "#   水平部分會隨機在(-img_widtha, img_widtha) 平移 垂直部分會隨機在(-img_heightb, img_heightb) 平移\n",
    "# scale: 縮放參數，為一個區段設定，defalut為keep原始圖片大小。 (a,b)縮放參數會在a-b之間隨機抽出一個數字。\n",
    "# shear: 圖像裁減參數，可以參考Crop的設定，defalut為不做裁減。\n",
    "# resample:An optional resampling filter 參考 https://pillow.readthedocs.io/en/latest/handbook/concepts.html#filters\n",
    "# fillcolor:圖像外部填充的顏色。 (Tuple for RGB Image and int for grayscale) 。\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.RandomAffine(degrees=(-30,30), translate=(0, 0.5), \n",
    "                            scale=(0.4, 0.5), shear=(0,0), fillcolor=(0,255,255))])\n",
    "new_img = transform(img_pil); new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 影像 Grayscale 和 RandomGrayscale  : Grayscale將圖片(PIL Image or torch tensor)轉換成灰階。\n",
    "# Grayscale 參數設定:\n",
    "# — num_output_channels (int，(1 or 3)): \n",
    "# 輸出圖像要幾個channel * 1: image is single channel * 3: image is 3 channel with r == g == b\n",
    "# RandomGrayscale 參數設定:\n",
    "# — p: 圖片要進行轉換灰階的機率。\n",
    "# note: RandomGrayscale和 Grayscale不同，如果輸入是channel數是1，輸出的灰階則是1個chnnel，\n",
    "# 如果輸入是三個channel，則輸出3 channel with r == g == b。\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.Grayscale(num_output_channels=1)])\n",
    "new_img = transform(img_pil)\n",
    "new_img_array = np.array(new_img)\n",
    "print(\"original shape:\", np.array(img_pil).shape)\n",
    "print(\"shape:\", new_img_array.shape); new_img.show()\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.Grayscale(num_output_channels=3)])\n",
    "new_img = transform(img_pil)\n",
    "new_img_array = np.array(new_img)\n",
    "print(\"original shape:\", np.array(img_pil).shape)\n",
    "print(\"shape:\", new_img_array.shape);new_img.show()\n",
    "ransform = transforms.Compose([ transforms.Resize((100,150)),\n",
    "    transforms.RandomGrayscale(p=0.9)])\n",
    "new_img = transform(img_pil)\n",
    "new_img_array = np.array(new_img)\n",
    "print(\"original shape:\", np.array(img_pil).shape)\n",
    "print(\"shape:\", new_img_array.shape);new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 影像 RandomPerspective 圖片(PIL Image or torch tensor)在給定的機率執行給定圖像的隨機透視變換。\n",
    "# 參數設定: # — distortion_scale (float): 控制失真(distortion)程度，範圍為0–1，default:0.5。\n",
    "#— p (float):執行轉換的機率，default: 0.5。 — interpolation (int):\n",
    "# Interpolation type。 — fill (n-tuple or int or float): 當圖扭曲後，圖外滿要填滿的值。\n",
    "transform = transforms.Compose([transforms.Resize((200,300)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=2)])\n",
    "new_img = transform(img_pil);new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 * 影像 ColorJitter  隨機調整圖片的亮度(brightness)、對比(contrast)、飽和度(saturation)和色調(hue)。\n",
    "# brightness:(float or tuple(min, max))亮度從[max(0,1-brightness),1+brightness]隨機取一個值，或是[min, max]，須為非負數。\n",
    "# contrast: (float or tuple(min, max))對比從[max(0, 1-contrast), 1+contrast]隨機取一個值，或是[min, max]，須為非負數。\n",
    "# saturation: (float or tuple(min, max)) 飽和度 從[max(0, 1-saturation), 1+saturation]隨機取一個值，\n",
    "# 或是[min, max]，須為非負數。\n",
    "# hue: (float or tuple(min, max)) 色調 從[-hue, hue]隨機取一個值，或是[min, max],\n",
    "# 但hue必須設定在[0,0.5]或-0.5<=min<=max<=0.5。\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.ColorJitter(brightness=(0, 5), contrast=(0, 5), saturation=(0, 5), hue=(-0.1, 0.1))])\n",
    "new_img = transform(img_pil); new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 15 影像 RandomRotation  將圖片隨機旋轉。\n",
    "# 參數設定:# degrees: (float or tuple(min, max)) 旋轉角度 從[-degrees, degrees]隨機取一個值，或是[min, max]。\n",
    "# resample: 選轉後的圖，外圍補值方式。\n",
    "# expand: (True or False) True: 將輸出圖況大到可以容納整張原始圖。 False: 輸出圖跟輸入圖一樣大，所以可能因為旋轉導致圖像被切斷。\n",
    "# center: (n-tuple or int or float) 在圖片的哪個位置做為中心進行旋轉，default: None (圖的正中心旋轉)。\n",
    "# fill: 同pad函數填滿方式，default: 0。\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(30, resample=Image.Resampling.BICUBIC, expand=False, center=(55, 5))])\n",
    "new_img = transform(img_pil); new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  16. 影像 RandomApply :從給定的機率下隨機執行全部的設定轉換組合。\n",
    "# 參數設定: # transforms (list or tuple or torch.nn.Module): list of transformations。\n",
    "# p (float):probability，default: 0.5。\n",
    "transform_set = [transforms.CenterCrop(200), transforms.Pad(100, padding_mode='symmetric'),\n",
    "             transforms.RandomRotation(30), transforms.ColorJitter()]\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.RandomApply(transform_set, p=0.5)]); new_img = transform(img_pil); new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. 影像 RandomChoice 和 RandomOrder\n",
    "# RandomChoice: 從設定的轉換組合隨機選取一個轉換執行。# RandomOrder: 從設定的轉換組合隨機打亂，全部執行。\n",
    "transform_set = [ transforms.CenterCrop(200),transforms.Pad(20, padding_mode='symmetric'),\n",
    "             transforms.RandomRotation(30),transforms.ColorJitter()]\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),\n",
    "    transforms.RandomChoice(transform_set)]) ;  new_img = transform(img_pil); new_img.show()\n",
    "transform_set = [ transforms.CenterCrop(200), transforms.Pad(20, padding_mode='symmetric'),\n",
    "             transforms.RandomRotation(30), transforms.ColorJitter()]\n",
    "transform = transforms.Compose([transforms.Resize((100,150)),transforms.RandomOrder(transform_set)])\n",
    "new_img = transform(img_pil) ; new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### CNN for real defect Image ============================\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "class CustomImageDataset(Dataset): # 繼承Dataset 類別 \n",
    "    def read_data_set(self):\n",
    "        all_img_files = []\n",
    "        all_labels = []\n",
    "        class_names = []\n",
    "        print('self.data_set_path=',self.data_set_path)\n",
    "        print('os.listdir(self.data_set_path=',os.listdir(self.data_set_path)) # ['Cr', 'Pa', 'Sc']\n",
    "        print('================================================================')\n",
    "        for index, i in enumerate(os.listdir(self.data_set_path)):\n",
    "            print('index = ',index)\n",
    "            print('i=',  i) # i 依序 = ['Cr', 'Pa', 'Sc'] \n",
    "            class_names.append(i)\n",
    "            for j in os.listdir(self.data_set_path+'/'+i):\n",
    "                all_img_files.append(self.data_set_path+'/'+i+'/'+j)\n",
    "                all_labels.append(index) # index :  Cr =0, Pa =1 , Sc =2\n",
    "        print(all_img_files)        \n",
    "        return all_img_files, all_labels, len(all_img_files), len(class_names)\n",
    "      \n",
    "    def __init__(self, data_set_path, transforms=None):\n",
    "        self.data_set_path = data_set_path\n",
    "        self.image_files_path, self.labels, self.length, self.num_classes = self.read_data_set()\n",
    "        self.transforms = transforms\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_files_path[index])\n",
    "        image = image.convert(\"RGB\")\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        label = self.labels[index]\n",
    "        return image, label\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "class CustomConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        self.layer1 = self.conv_module(3, 16)\n",
    "        self.layer2 = self.conv_module(16, 32)\n",
    "        self.layer3 = self.conv_module(32, 64)\n",
    "        self.layer4 = self.conv_module(64, 128)\n",
    "        self.layer5 = self.conv_module(128, 256)\n",
    "        self.gap = self.global_avg_pool(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(-1, num_classes)   # num_classes =3 分3類\n",
    "        return out\n",
    "    def conv_module(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    def global_avg_pool(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)))\n",
    "hyper_param_epoch = 10\n",
    "hyper_param_learning_rate = 0.001\n",
    "hyper_param_batch = 32\n",
    "transforms_train = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.RandomRotation(10.),\n",
    "                                       transforms.ToTensor()])\n",
    "transforms_test = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                      transforms.ToTensor()])\n",
    "train_data_set = CustomImageDataset(data_set_path=\"./data_manufacture/train\", transforms=transforms_train)\n",
    "train_loader = DataLoader(train_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
    "test_data_set = CustomImageDataset(data_set_path=\"./data_manufacture/validation\", transforms=transforms_test)\n",
    "test_loader = DataLoader(test_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
    "num_classes = train_data_set.num_classes\n",
    "custom_model = CustomConvNet(num_classes=num_classes).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)\n",
    "# trainong ==============================================\n",
    "for e in range(hyper_param_epoch):\n",
    "    for i_batch, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = custom_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(loss)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(e + 1, hyper_param_epoch, loss.item()))\n",
    "# Test the model\n",
    "custom_model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels  in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = custom_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(labels)\n",
    "         \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
