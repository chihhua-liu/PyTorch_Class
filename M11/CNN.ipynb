{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 11.Demo 11 : CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MNIST =============================\n",
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.Normalize((0.5), (0.5))])\n",
    "trainset = mnist.MNIST('./dataset/mnist', train=True, transform=transform, download=True)\n",
    "testset = mnist.MNIST('./dataset/mnist', train = False, transform=transform, download=True)\n",
    "train_data = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "for im, label in train_data:\n",
    "    print(im.shape);  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0) #output_shape=(16,24,24)\n",
    "        self.relu1 = nn.ReLU() # activation\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2) #output_shape=(16,12,12)#Max pool 1\n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0) #output_shape=(32,8,8)\n",
    "        self.relu2 = nn.ReLU() # activation\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2) #output_shape=(32,4,4) # Max pool 2\n",
    "        # Fully connected 1 ,#input_shape=(32*4*4)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 10)\n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        x = self.cnn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)  # Max pool 1\n",
    "        x = self.cnn2(x) # Convolution 2 \n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)  # Max pool 2 \n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Linear function (readout)\n",
    "        x = self.fc1(x) ; return x\n",
    "model = CNN().to(device)  # build model\n",
    "criterion = nn.CrossEntropyLoss()  # define cost\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.1) # optimization\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), 0.01, alpha=0.9)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), 0.01, betas=(0.9, 0.99))\n",
    "losses = [] ; acces = [] ; eval_losses = [] ;eval_acces = []\n",
    "for epoch in range(5):\n",
    "    train_loss = 0 ;    train_acc = 0 ;    model.train()      \n",
    "    for im, label in train_data:\n",
    "        im = im.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(im)\n",
    "        loss = criterion(pred, label)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, pred = pred.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / im.shape[0]\n",
    "        train_acc += acc\n",
    "    losses.append(train_loss / len(train_data))\n",
    "    acces.append(train_acc / len(train_data))\n",
    "    eval_loss = 0 ;    eval_acc = 0   ;    model.eval()\n",
    "    for im, label in test_data:\n",
    "        im = im.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(im)\n",
    "        loss = criterion(pred, label)\n",
    "        eval_loss += loss.item()\n",
    "        _, pred = pred.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / im.shape[0]\n",
    "        eval_acc += acc\n",
    "    eval_losses.append(eval_loss / len(test_data))\n",
    "    eval_acces.append(eval_acc / len(test_data))\n",
    "    print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}, Eval Loss: {:.6f}, Eval Acc: {:.6f}'\n",
    "          .format(epoch, train_loss / len(train_data), train_acc / len(train_data), eval_loss / len(test_data), eval_acc / len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,5),losses)\n",
    "plt.plot(np.arange(0,5),eval_losses)\n",
    "plt.title('Model  Loss');plt.xlabel('Epoch')  ; plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper right'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,5),acces)\n",
    "plt.plot(np.arange(0,5),eval_acces)\n",
    "plt.title('Model  Accuracy')\n",
    "plt.xlabel('Epoch') ;  plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'], loc='upper right') ;plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cifar10 ========================================\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10_data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                            shuffle=True, num_workers=2)  # num_workers=2: CPU開雙核心\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10_data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) ;  plt.show() # pytorch 深度要放最後\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader) ; images, labels = dataiter.next()\n",
    "# show images : torchvision.utils.make_grid(images) show 一堆image\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4))) # # print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x);   return x\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data # # get the inputs; data is a list of [inputs, labels]\n",
    "        optimizer.zero_grad()  # zero the parameter gradients  \n",
    "        outputs = net(inputs)  # forward + backward + optimize\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()   # print statistics\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)  # net.state_dict() : 只有存參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images)) # print images\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0 ;total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat and Dog Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "class CustomImageDataset(Dataset):\n",
    "    def read_data_set(self):\n",
    "        all_img_files = []\n",
    "        all_labels = []\n",
    "        class_names = []\n",
    "        for index, i in enumerate(os.listdir(self.data_set_path)):\n",
    "            class_names.append(i)\n",
    "            for j in os.listdir(self.data_set_path+'/'+i):\n",
    "                all_img_files.append(self.data_set_path+'/'+i+'/'+j)\n",
    "                all_labels.append(index)\n",
    "        #print(all_img_files)\n",
    "        #print(all_labels)\n",
    "        return all_img_files, all_labels, len(all_img_files), len(class_names)\n",
    "    def __init__(self, data_set_path, transforms=None):\n",
    "        self.data_set_path = data_set_path\n",
    "        #self.read_data_set2()\n",
    "        self.image_files_path, self.labels, self.length, self.num_classes = self.read_data_set()\n",
    "        self.transforms = transforms\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_files_path[index])\n",
    "        image = image.convert(\"RGB\")\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        label = self.labels[index]\n",
    "        return image, label\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "class CustomConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        self.layer1 = self.conv_module(3, 16)\n",
    "        self.layer2 = self.conv_module(16, 32)\n",
    "        self.layer3 = self.conv_module(32, 64)\n",
    "        self.layer4 = self.conv_module(64, 128)\n",
    "        self.layer5 = self.conv_module(128, 256)\n",
    "        self.gap = self.global_avg_pool(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(-1, num_classes)\n",
    "        return out\n",
    "    def conv_module(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    def global_avg_pool(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)))\n",
    "hyper_param_epoch = 3\n",
    "hyper_param_batch = 32\n",
    "hyper_param_learning_rate = 0.001\n",
    "transforms_train = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.RandomRotation(10.),\n",
    "                                       transforms.ToTensor()])\n",
    "transforms_test = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                      transforms.ToTensor()])\n",
    "train_data_set = CustomImageDataset(data_set_path=\"./data/train\", transforms=transforms_train)\n",
    "train_loader = DataLoader(train_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
    "test_data_set = CustomImageDataset(data_set_path=\"./data/test\", transforms=transforms_test)\n",
    "test_loader = DataLoader(test_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
    "num_classes = train_data_set.num_classes\n",
    "custom_model = CustomConvNet(num_classes=num_classes).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)\n",
    "for e in range(hyper_param_epoch):\n",
    "    for i_batch, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = custom_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i_batch + 1) % hyper_param_batch == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                  .format(e + 1, hyper_param_epoch, loss.item()))\n",
    "# Test the model\n",
    "custom_model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels  in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = custom_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat and Dog Classification(ImageFolder)\n",
    "####  ImageFolder API  for  image用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "transforms_train = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.RandomRotation(10.),\n",
    "                                       transforms.ToTensor()])\n",
    "train_data_set = ImageFolder('./data/train', transform=transforms_train)\n",
    "print(train_data_set.class_to_idx)\n",
    "print(train_data_set.imgs[:5])\n",
    "print(train_data_set[0][1])\n",
    "print(train_data_set[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "class CustomConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        self.layer1 = self.conv_module(3, 16)\n",
    "        self.layer2 = self.conv_module(16, 32)\n",
    "        self.layer3 = self.conv_module(32, 64)\n",
    "        self.layer4 = self.conv_module(64, 128)\n",
    "        self.layer5 = self.conv_module(128, 256)\n",
    "        self.gap = self.global_avg_pool(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(-1, num_classes)\n",
    "        return out\n",
    "    def conv_module(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    def global_avg_pool(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)))\n",
    "hyper_param_epoch = 3\n",
    "hyper_param_batch = 32\n",
    "hyper_param_learning_rate = 0.001\n",
    "transforms_train = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.RandomRotation(10.),\n",
    "                                       transforms.ToTensor()])\n",
    "transforms_test = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                      transforms.ToTensor()])\n",
    "train_data_set = ImageFolder('./data/train', transform=transforms_train)\n",
    "train_loader = DataLoader(train_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
    "test_data_set = ImageFolder('./data/test', transform=transforms_test)\n",
    "test_loader = DataLoader(test_data_set, batch_size=hyper_param_batch, shuffle=True)\n",
    "num_classes = len(train_data_set.class_to_idx)\n",
    "custom_model = CustomConvNet(num_classes=num_classes).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)\n",
    "for e in range(hyper_param_epoch):\n",
    "    for i_batch, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)        \n",
    "        # Forward pass\n",
    "        outputs = custom_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i_batch + 1) % hyper_param_batch == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                  .format(e + 1, hyper_param_epoch, loss.item()))\n",
    "# Test the model\n",
    "custom_model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels  in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = custom_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy on the {} test images: {} %'.format(total, 100 * correct / total))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
