{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoUstv99Iqoo"
   },
   "source": [
    "### Demo20 MNIST for LSTM & GRU(new RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5ZcSWHmIqos",
    "outputId": "217c044e-5d13-4b4e-88c3-3412ad6a10dd"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "# Hyper-parameters\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./dataset/mnist',train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./dataset/mnist',train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,shuffle=False)\n",
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie Review  * reviews.txt is 電影評論 * labels.txt is answer : 正評 or 負評"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSNEdSjnIqoz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# read data from text files\n",
    "with open('./data/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('./data/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFQ-tWAbIqo0",
    "outputId": "72920528-ce6f-4a96-fc08-ad1ebd891d5d"
   },
   "outputs": [],
   "source": [
    "print(reviews[:1000])\n",
    "print(labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qajXcSMIqo0"
   },
   "outputs": [],
   "source": [
    "# # punctuation （全部）標點符號:!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "from string import punctuation  \n",
    "# get rid of punctuation\n",
    "reviews = reviews.lower() # lowercase, standardize\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])  # 移除全部標點符號\n",
    "print(all_text[:1000])\n",
    "# split by new lines and spaces\n",
    "reviews_split = all_text.split('\\n') # 每一句被斷開\n",
    "all_text = ' '.join(reviews_split)\n",
    "# create a list of words\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-tv67LLIqo0",
    "outputId": "3ef67f94-3f41-49be-96d3-7619687a0822"
   },
   "outputs": [],
   "source": [
    "words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1HSaR_MIqo1"
   },
   "outputs": [],
   "source": [
    "# feel free to use this import \n",
    "from collections import Counter\n",
    "## Build a dictionary that maps words to integers\n",
    "counts = Counter(words)\n",
    "# print('counts = \\n',counts)\n",
    "# print(\"==================================================\")\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)  # 由高排到低\n",
    "# print('vocab=\\n',vocab[:500])\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "# print('vocab_to_int=\\n',vocab_to_int)\n",
    "## use the dict to tokenize each review in reviews_split\n",
    "## store the tokenized reviews in reviews_ints\n",
    "reviews_ints = []\n",
    "for review in reviews_split:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])\n",
    "print(reviews_ints[:100])\n",
    "# stats about vocabulary\n",
    "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
    "# print tokens in first review\n",
    "print('Tokenized review: \\n', reviews_ints[:1])  # 第一筆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJ7paXZQIqo1"
   },
   "outputs": [],
   "source": [
    "# 1=positive, 0=negative label conversion\n",
    "labels_split = labels.split('\\n')\n",
    "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])\n",
    "# outlier review stats\n",
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QW8EY45Iqo2",
    "outputId": "470d4966-1506-44aa-dae4-dc3edf1ed036"
   },
   "outputs": [],
   "source": [
    "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
    "## remove any reviews/labels with zero length from the reviews_ints list.\n",
    "# get indices of any reviews with length 0\n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "# remove 0-length reviews and their labels\n",
    "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
    "print('Number of reviews after removing outliers: ', len(reviews_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqtxAyKvIqo2"
   },
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length. '''\n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ksLyU7NIqo3",
    "outputId": "d745d8b9-1ae9-46c0-aa6e-3a9ab43d1672"
   },
   "outputs": [],
   "source": [
    "# Test your implementation!\n",
    "seq_length = 200\n",
    "features = pad_features(reviews_ints, seq_length=seq_length)\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[:30,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyvC4M3pIqo3",
    "outputId": "52f84ed4-553a-492a-8096-3a04cd252b3a"
   },
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPIPlJGJIqo3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "#create Tensor datasets : torch.from_numpy() : numpy 轉換成 tensor =============\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "batch_size = 50   \n",
    "# dataloaders make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5RxR9XlIqo3",
    "outputId": "914de9b5-392f-4cc0-c629-6a8b126df25f"
   },
   "outputs": [],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)\n",
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqZnbIWtIqo4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"  The RNN model that will be used to perform Sentiment analysis.    \"\"\"\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"       Initialize the model by setting up the layers.        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)#embedding layer:字ID變向量 \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\" Perform a forward pass of our model on some input and hidden state. \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out[:, -1, :] # getting the last time step output\n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),  # c state\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())  # h state\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SgoGIJSIqo4",
    "outputId": "1a112f66-5c74-40ef-8e6f-31b4f4e67bad"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1; embedding_dim = 128; hidden_dim = 64 ; n_layers = 2\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCSo7QttIqo4"
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001 ;  criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VRCM1d_Iqo4",
    "outputId": "4d71f3f9-bb81-4c4c-d713-4979a2fb5c07"
   },
   "outputs": [],
   "source": [
    "# training params\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "counter = 0  ; print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtLTjIOvIqo5",
    "outputId": "6985917d-7b46-4c55-a1fe-22f3f52675d8"
   },
   "outputs": [],
   "source": [
    "# Get test data loss and accuracy\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)  ;  net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaf0tQrcIqo5"
   },
   "outputs": [],
   "source": [
    "# positive test review\n",
    "# test_review_pos = 'This movie had the best acting and the dialogue was so good. I loved it.'\n",
    "# negative test review\n",
    "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjZZqstGIqo5",
    "outputId": "d5647621-bf27-4d7b-986a-6f612c6fdc48"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def tokenize_review(test_review):\n",
    "    test_review = test_review.lower() # lowercase\n",
    "    # get rid of punctuation\n",
    "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
    "    # splitting by spaces\n",
    "    test_words = test_text.split()\n",
    "    # tokens\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab_to_int.get(word, 0) for word in test_words])\n",
    "    return test_ints\n",
    "# test code and generate tokenized review\n",
    "test_ints = tokenize_review(test_review_neg)\n",
    "print(test_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oESXq9Y0Iqo5",
    "outputId": "0c566d9c-1e9c-4486-ab96-dd4c4ce86364"
   },
   "outputs": [],
   "source": [
    "# test sequence padding\n",
    "seq_length=200 ; features = pad_features(test_ints, seq_length)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OeiYKdjIqo5",
    "outputId": "4d0eea7d-6958-4dc5-c4ec-d29f1433446e"
   },
   "outputs": [],
   "source": [
    "# test conversion to tensor and pass into your model\n",
    "feature_tensor = torch.from_numpy(features) ; print(feature_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kAHl12pIqo6"
   },
   "outputs": [],
   "source": [
    "def predict(net, test_review, sequence_length=200):\n",
    "    net.eval()\n",
    "    # tokenize review\n",
    "    test_ints = tokenize_review(test_review)\n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    batch_size = feature_tensor.size(0)\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    if(train_on_gpu):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    # get the output from the model\n",
    "    output, h = net(feature_tensor, h)\n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze()) \n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive review detected!\")\n",
    "    else:\n",
    "        print(\"Negative review detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVXMTFQDIqo6",
    "outputId": "8ab298ce-4199-4d27-853d-cbcd070833df"
   },
   "outputs": [],
   "source": [
    "# call function\n",
    "seq_length=200 # good to use the length that was trained on\n",
    "predict(net, test_review_neg, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NqAtjj4KLF0"
   },
   "outputs": [],
   "source": [
    "mylist =['apple','banana','orange']\n",
    "result = ''.join(mylist)  ;  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Simple_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
